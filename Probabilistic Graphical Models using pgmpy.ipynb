{
 "metadata": {
  "name": "",
  "signature": "sha256:0f0e689628b49126b60ecca1766ec7b85e18de79da0d5fce8fc1105d1c4a5fad"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image, Math"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### General classification problem in Machine learning\n",
      "\n",
      "To find the probability of a the class of a new data point given the training data and a new data point i.e  $ P(C | x, D) $.\n",
      "\n",
      "So, if we have the joint Probability distribution over all the variables we can easily marginalize and reduce this probability distribution to find the values for the new data point."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Probabilistic Graphical Models (PGM)\n",
      "\n",
      "Probabilistic Graphical Model is a way of compactly representing Joint Probability distribution over random variables by exploiting the independence conditions of the variables. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### How is PGM different than other techniques?\n",
      "\n",
      "The distinctive thing about PGM is that it provides a very intuitive and natural approach for modelling complex problems along with maintaining control over the computational costs."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Example \n",
      "\n",
      "Let's see an example for predicting the price of a house. For simplicity we will consider that the price of the house depends only on Area, Location, Furnishing, Crime Rate and Distance from the airport. And also we will consider that all of these are discrete variables."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Our raw data would look something like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "raw_data = np.random.randint(low=0, high=2, size=(1000, 6))\n",
      "print(raw_data)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 0 1 1 1 0]\n",
        " [1 1 0 1 0 0]\n",
        " [1 1 1 1 0 1]\n",
        " ..., \n",
        " [0 0 1 0 1 0]\n",
        " [0 0 1 0 0 1]\n",
        " [0 0 0 1 1 1]]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Now let's create a model for the interaction of our variables using intuition:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "<img src=\"files/housing_price_small.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "<img src=\"files/housing_price.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Let's create this model using pgmpy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pgmpy.models import BayesianModel\n",
      "import pandas as pd\n",
      "data = pd.DataFrame(raw_data, columns=['A', 'C', 'D',\n",
      "                                       'L', 'F', 'P'])\n",
      "data_train = data[: int(data.shape[0] * 0.75)]\n",
      "\n",
      "model = BayesianModel([('F', 'P'), ('A', 'P'),\n",
      "                       ('L', 'P'), ('C', 'L'),\n",
      "                       ('D', 'L')])\n",
      "model.fit(data_train)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### What does fit does ?\n",
      "The fit method adds a Conditional Probability Distribution (CPD) to each of the node in our model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "<img src='files/housing_price_with_CPD.png'>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.get_cpds()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "[<pgmpy.factors.CPD.TabularCPD at 0x7ffbf81f4bd0>,\n",
        " <pgmpy.factors.CPD.TabularCPD at 0x7ffbf81e2b50>,\n",
        " <pgmpy.factors.CPD.TabularCPD at 0x7ffbd670b5d0>,\n",
        " <pgmpy.factors.CPD.TabularCPD at 0x7ffbfd154dd0>,\n",
        " <pgmpy.factors.CPD.TabularCPD at 0x7ffbd668c110>,\n",
        " <pgmpy.factors.CPD.TabularCPD at 0x7ffbd668c0d0>]"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.get_cpds('P')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "html": [
        "<table><caption>TabularCPD for <b>P</b></caption><tr><td><b>L</b></td><td colspan=4>L_0</td><td colspan=4>L_1</td></tr><tr><td><b>F</b></td><td colspan=2>F_0</td><td colspan=2>F_1</td><td colspan=2>F_0</td><td colspan=2>F_1</td></tr><tr><td><b>A</b></td><td colspan=1>A_0</td><td colspan=1>A_1</td><td colspan=1>A_0</td><td colspan=1>A_1</td><td colspan=1>A_0</td><td colspan=1>A_1</td><td colspan=1>A_0</td><td colspan=1>A_1</td></tr><tr><td><b>P_0</b></td><td>0.4747</td><td>0.5000</td><td>0.5610</td><td>0.5979</td><td>0.3913</td><td>0.5333</td><td>0.5684</td><td>0.5368</td></tr><tr><td><b>P_1</b></td><td>0.5253</td><td>0.5000</td><td>0.4390</td><td>0.4021</td><td>0.6087</td><td>0.4667</td><td>0.4316</td><td>0.4632</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "<pgmpy.factors.CPD.TabularCPD at 0x7ffbfd154dd0>"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "But the data that we have for training might be baised so with pgmpy we also have the option to assign your own Conditional Probability Distributions. Let's say the probability of getting an unfurnished home is equal to getting a furnished house. Let's adjust the values according to this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pgmpy.factors import TabularCPD\n",
      "f_cpd = TabularCPD('F', 2, [[0.5], [0.5]])\n",
      "\n",
      "model.remove_cpds('F')\n",
      "model.add_cpds(f_cpd)\n",
      "\n",
      "print(model.check_model())"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Now let's try to do some reasoning on our model to verify if our intuitution for the model was correct or not."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pgmpy.inference import VariableElimination\n",
      "infer = VariableElimination(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query_result = infer.query(variables=['A'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query_result['A']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><caption>Factor</caption>\n",
        "<tr><td><b>A</b></td><td><b>phi(A)</b><d></tr>\n",
        "<tr><td>A_0</td><td>0.5040</td></tr>\n",
        "<tr><td>A_1</td><td>0.4960</td></tr>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "<pgmpy.factors.Factor.Factor at 0x7ffbd670b390>"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Returns a probability distribution over variables A and B.\n",
      "query_result_with_evidence = infer.query(variables=['P'],\n",
      "                                         evidence={'L': 0, 'F': 0, 'A': 0})"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query_result_with_evidence['P']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><caption>Factor</caption>\n",
        "<tr><td><b>P</b></td><td><b>phi(P)</b><d></tr>\n",
        "<tr><td>P_0</td><td>0.4747</td></tr>\n",
        "<tr><td>P_1</td><td>0.5253</td></tr>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "<pgmpy.factors.Factor.Factor at 0x7ffbd66cdd10>"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "If you think about prediction about new values from this model, it is basically the same what we have been doing here. We basically ask questions about the probability of some variable giving conditions for other variables. Also we can account for missing values with just leaving it blank."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Why to use PGM rather than simply computing these values from the probaility distribution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "The graph structure implies some independence conditions over the variables. The variables can be indirectly connected to each other in the following ways:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "<img src='files/connection.png'>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "This independence due to the structure is responsible for the reduced computational complexity for inference.\n",
      "\n",
      "For the Joint Probability distribution over all the variables we can write it as:\n",
      "\n",
      "$$ P(A, C, D, L, F, P) = P(A) * P(C | A) * P(D | A, C) * P(L | A, C, D) * P(F | A, C, D, L) * P(P | A, C, D, L, F) $$\n",
      "\n",
      "But if we apply all the independency conditions that we saw above in this equation we get:\n",
      "\n",
      "$$ P(A, C, D, L, F, P) = P(A) * P(L | C, D) * P(C) * P(D) * P(P | F, A, L) * P(F)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "For doing inference over this model we can simply eliminate variables or condition this joint probability.\n",
      "\n",
      "Say if we want to calcualate $ P(A) $ we could simply calculate:\n",
      "\n",
      "$$P(A) =  \\sum_{C} \\sum_{D} \\sum_{L} \\sum_{F} \\sum_{P} P(A, C, D, L, F, P) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "This algorithm of summing over variables that are not required is known as Variable Elimination."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### How to construct model from the data?\n",
      "\n",
      "Doing inference from the model is really simple. But the tough part is to create the model from the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The house price estimation example had very intuitive variables and thus we were able to construct the model very easily. But this is not always the case.\n",
      "\n",
      "So for constructing the model we use the independence properties implied by the model and by the Joint Probability distribution."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "One of the simplest way to construct a model is to find out some independence conditions in the data and according to that we can use that to arrange our variables in the graph structure in such a way to satisfy those independency conditions."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Also local independencies make it simpler to construct models. Give example of local independencies in the case of Bayesian Models."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "These were the most basic ways for constructing models from distributions. There are many more ways of finding structure in data to properly model them like density estimation etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}